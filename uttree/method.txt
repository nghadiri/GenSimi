Methodology
This study proposes a UTTree (Unstructured Temporal Tree) model to represent patient information. The model combines the structured data and textual information of the EMR recorded in the latest visit of the patient using a tree structure, as described in Section 3.1. Additionally, the model is enhanced by the patients' medical history in their EMR. Section 3.2 explains the extended model, UTTree-H (Unstructured Temporal Tree with History). The two methods are different in the way they implement the relabeling mechanism. This difference can be found in the workflow shown in Fig. 1 (steps 2-b and 2-c).
The UTTree
This model aims to combine structured and unstructured data and give the combined data as input to the document representation algorithm. We combined the data using a tree structure. The following explains how trees are created.
The model's input is a database containing the various types of information recorded in the EMRs of several patients, and its output is the degree of similarity between every two patients. According to the proposed algorithm, the degree of similarity is calculated by comparing the cosine distance of the embedded vectors generated for each patient. The output of the proposed algorithm is compared with the ideal similarity scores. This section continues with an explanation of the different parts of the workflow. Fig. 1 depicts the main steps of the algorithm in a workflow diagram.

 
Fig. 1. Overview of the proposed method. First, in step 1, EMR data for each patient is taken from the dataset (1-a). Afterward, structured and unstructured data are preprocessed separately (1-b). The preprocessed data are homogenized using a data structure called quadruple (1-c). Step 2 algorithm uses quadruple to develop a tree structure (2-a). Next, two relabeling processes are conducted to assign labels to non-leaf nodes. The UTTree model uses only new detected findings (red nodes) and real-time data (yellow nodes) (2-b) for relabeling the non-leaf nodes in the middle level of the tree.
In contrast, the UTTree-H model uses retrospective data, as well, for assigning labels to non-leaf nodes. The output of the second phase is a tree structure for each patient, in which all nodes have labels. In step 3, traversing the tree (3-a) provides rich sequences (3-b), which are used as inputs for step 4. In step 4, the sequences are represented through the document representation algorithm to generate embedding vectors for patients. Finally, the cosine distance between the vectors is considered the similarity score. For each patient, the most similar K patients are returned (5).
Data preprocessing: In the first phase, the goal is to identify a person's previous and current diseases from the descriptions written in clinical texts. Since signs and symptoms describe the diseases in medical texts, all terms related to diseases, signs, and symptoms are extracted and grouped according to their section headers in medical notes. After section detection, the algorithm employs UMLS to extract concepts for each expression. The information about prescriptions and laboratory tests is also extracted. A quadruple data structure is used to homogenize the structure of information extracted from structured and unstructured sources that provide the basis for combining information. 
Creating the tree structure and relabeling: The quadruples are applied in developing a temporal tree model. We create a subtree for each time window. There are branches for each data type (disease, prescription, laboratory tests). In each subtree branch, the medical events related to that time window and datatype are leaf nodes. In the tree's construction, a modified model of the Weisfeiler-Lehman graph kernels [35] relabeling method is used to compare graphs that capture topological and label information. Using these kernel co-occurrences, the relation between levees in each subtree (medical events) converts to rich compounds in non-leaf nodes. In this step, two relabeling methods are used. In the first method, the extracted medical events related to the same visit are used in relabeling non-leaf nodes. In the second method described in section UTTree-H, patient medical history data are also used.
Traversing the tree: In the third step, traversing the temporal tree using the BFS method yields sequences, which are used as inputs of the embedding algorithm to represent patient information as vectors. 
Document representation: The result of tree traversal is a sequence of components, i.e., a new document for each patient. This document serves as the input of the representation algorithm. This study employs the Doc2Vec algorithm (Le and Mikolov, 2014), a sentence embedding method [36] used to create a vectorized representation of a group of words taken collectively as a single unit, rather than giving only the simple average of the words in the sentence. 
Downstream task: The embedding vectors are fed to the patient similarity assessment model. It works based on the cosine distance between patient embedding vectors and the gold standard to measure model accuracy. The results obtained from this method are compared with several baselines. The details of each stage are presented in the following.
Data preprocessing
Unstructured data processing: We define the process of automatically extracting clinical concepts from unstructured clinical notes in EMRs. A large amount of the information in an electronic patient record system is unstructured in the form of free text [37]. Clinical text is written by various professionals such as physicians, nurses, physiotherapists, and psychologists. It is often written under time pressure and contains misspellings, non-standard abbreviations, jargon, and incomplete sentences. Therefore, it is challenging to employ natural language processing (NLP) tools mainly developed for other text types [38].
Clinical notes in EMRs contain different text types, such as discharge notes, nursing reports, and pharmacy notes. Each standard clinical note, especially a discharge note, consists of several components or sections [39]. However, there is significant variation in sections and the descriptive phrases in section headers. This challenge in the NLP of clinical notes is named flexible formatting (37, 40). In this study, we consider the effect of the patients' medical history in interpreting their new clinical conditions. Therefore, the first step must differentiate between the patients' medical history (previous active or resolved medical conditions) and new findings. After sectioning each note by MedspaCy [40], we follow the next step, named-entity recognition (NER). In this step, medical named entities, such as diseases, are recognized from medical texts. This step is necessary for representing a complete overview of a patient's medical history and current significant findings. We use MetaMap [41] for this step. 
Finally, we perform concept encoding to map the extracted terms to standard terminologies. A doctor may express the same disease differently, so mapping based on ontology is crucial. In this step, different forms of one disease are automatically mapped to one preferred name. In this process, associated concepts are retrieved from MetaMap (42) and sorted according to their similarity to the searched term. Each term is assigned the concept with the highest score returned by MetaMap. After the concept mapping, the extracted concepts are sorted by registration time. During (1-a), the input notes are batched into a set of records. Each record includes the original phrase, note type (discharge, nursing, and reporting.), section category, registration time, negation tag, semantic type, and concept ID of each extracted phrase. The tools and libraries used in this process are listed in Appendix A.1.
Structured data processing: EMRs contain several structured data types. This study uses data on prescriptions, laboratories, and procedures. Structured data types are captured using controlled vocabularies rather than narrative text. Healthcare providers usually use the LOINC  standard for identifying laboratory tests or the RxNorm  the standard for identifying clinical drugs. Lab test results are usually documented, as well. Depending on age, gender, and other characteristics, this result is interpreted as low, usual, or high. In this study, we use these categories rather than the original values.
Harmonization of extracted data: To harmonize extracted information from clinical notes and structured parts of EMR, we introduce a flat format called quadruple. The quadruple data structure format consists of four components listed in Table. 2: time (t), event type (y), event (e), and value (v), which are represented by {t_i,y_i,e_i,v_i}, 1≤i≤n. The parameter n is the total number of extracted information. Patients can have different numbers of quadruples.
Table 2. Components of quadruple
Component	Definition
Time - t_i	The timestamp that each clinical event registers in the EMR.
Temporal Event role - y_i	The following temporal roles were taken into consideration in extracted disease in EMR:
Retrospective data (a): This role is assigned to the concepts extracted by processing medical history texts. 
New detected finding with a long-lasting effect (b): every disease registers in the current visit. We hypothesized that disease has more lasting effects than other medical events.
Real-time data with a short-term effect (c): The parameter used to model medical events other than a disease, such as laboratory results and prescribed drugs. These items are updated more frequently than disease events. Thus, they are only used to create subtrees (time windows) in which they are recorded.    
Event - e_i	The extractable medical event type (disease, sign, symptom, drug, lab, procedure.)
Value - v_i	The extractable medical event value

Creation of tree structure and relabeling
This phase includes two steps: creating a tree and relabeling non-leaf nodes by Weisfeiler-Lehman graph kernels [35].
Creating the tree: A four-level tree is created for each patient rooted by the patient identifier.
Each tree has subtrees at its second level. The number of subtrees is equal to the number of nonempty time windows. The user defines the length of the time window. Herein, we use a one-day time window. According to Table 2, the time field determines the number of included quadruples in each time window. The algorithm creates branches in subtrees for each nonempty temporal event role at the third level of the tree. As mentioned in Table 2, there are three temporal event roles. Thus, the third level of each subtree can have up to three different nodes. The first one is for retrospective data, the second for new detected findings with a long-lasting effect, and the last is related to real-time data with a short-term impact. The fourth level adds each pair of extracted values and event types. As mentioned in Table 2, event types could be disease, sign, symptom, drug, laboratory, and procedure. By the end of this phase, we have a four-level tree in which only leaf nodes have labels. The non-leaf nodes are relabeled in the next step. The pseudo-code can be found in Appendix A.5 in the supplementary files.
 
Fig. 2. An example of creating and relabeling a tree. At the top of figure (a), we see a quadruple set to construct the subtree(ti+1), containing five records. The main steps in Fig. 1 indicate that only leaf nodes on level 4 are labeled after the tree is created. Through the relabeling step, the non-leaf nodes of the higher levels are labeled in order. The UTTree method takes into account the current visit information for relabeling, while the UTTree-H method uses the past history of the patient, as well.
Relabeling: Relabeling non-leaf nodes in the tree allows us to capture the relationship between different medical events. Fig. 2 shows an example. This phase is completed using the Weisfeiler-Lehman kernel, which is designed for graphs and consists of four steps: multiset-label determination, sorting, label comparison, and relabeling. Only the leaf nodes have labels in the tree created in the previous step, and they can only be accessed through their parent nodes. As a result of two rounds of relabeling, the tree's root turns into a combination of medical events that occur within a specified time window. Fig. 2 shows the mechanisms of relabeling non-leaf nodes, focusing on Part 2-b of Fig. 1. Each subtree corresponds to a time window determined by the field "Time" in the quadruple. In the relabeling step, three approaches are used to change the labels of non-leaf nodes based on leaf nodes' labels. In the following sections, the three methods, namely the temporal tree [6], UTTree (the proposed model), and UTTree-H (the enhanced proposed model described in the next section), are applied. The temporal tree approach only relabels real-time nodes (yellow ones). In the UTTree approach, the nodes of newly detected findings (red ones) and real-time data are also used.
Traverse Tree
In this phase, we have a tree in which all leaf and non-leaf nodes have labels.
The tree can be traversed to generate sequences of terms. The traversal of a tree data structure is the process of visiting each node in the tree exactly once. It is classified by the order based on which the nodes are visited. This study uses the breadth-first search (BFS) traverse method. In breadth-first search (BFS) or level-order search, the search tree is broadened as much as possible before going to the next depth. Fig. 3 shows sequences created after tree traversing.

 
Fig. 3. Temporal sequences in the BFS order generated for the tree with four levels are shown in Fig 2; during the relabeling process, all leaf and non-leaf nodes of the tree are labeled in step 3 of the workflow. A sequence is generated for each tree level when the tree is traversed in the BFS order. The sequences combine to form the final document for each patient.
Patient representation
We have now reached a stage where we can generate embedding vectors for individual patients using document representation methods. Sequences created in the previous step are represented using the document representation technique. In document representation, the semantics of a document is encapsulated in real-valued vectors, which can be manipulated in downstream tasks. Relabeling results in documents that demonstrate the co-occurrence of medical events. Doc2Vec is one of the most popular ways of representing documents.
The Doc2Vec is based on Word2Vec [42][43] and uses an unsupervised learning approach to learn the document representation [44]. The input text (in our case, medical events) per document (in our case, temporal tree) can be varied, while the output is fixed-length vectors. 
The Doc2Vec includes two methods. The Distributed Memory Model of Paragraph Vectors (PV-DM)[45] is similar to the continuous bag-of-words approach in Word2Vec. The other method used in Doc2Vec is the Distributed Bag-of-Words version of Paragraph Vector (PV-DBOW) [46], which is similar to the skip-gram approach in Word2Vec. The PV-DM model computes the probability of a target word in a lexical context based on the surrounding words. The document is mathematically expressed as below in Equation 1:
∑_(tϵT_w)^▒log p(w_t |C_t,d_t)
(1)

where w_t is the target word, T_w is the set of training words, C_t=[w_(t-L),⋯,w_(t-1),w_(t+1),⋯,w_(t+L)] are context words that occur within a window size of L words around w_t, and d_t denotes the document corresponding to the t_th  training instance. There are two optimization methods for Doc2Vec: hierarchical softmax and negative sampling. In this study, we use the former. The experiments providing better results for this optimization method are listed in Appendix A.3.
Downstream Tasks
Using the representations produced in this step, we perform two types of downstream tasks, i.e., calculating patient similarity and predicting patient mortality. Section 4 examines the generated representations based on this downstream task. In this study, the main objective is to evaluate patient similarity. In this task, the score of similarity with other patients is calculated and sorted in descending order for each query patient in the dataset. The top K patients on the sorted list are returned as output to the algorithm. Moreover, the generated vectors are used to predict mortality, which is a supervised classification task.
UTTree-H
The UTTree is modeled using data from current admissions. As a part of the relabeling process, the model UTTree-H incorporates the patients' history. Due to this difference, the final generated sequences can include a combination of current clinical events and patient history. Therefore, the final representation is influenced by the patient history. In the UTTree-H, all three types of temporal event data are used to label non-leaf nodes.
An example is provided in Fig. 4 to illustrate the importance of using concepts extracted from the past history of patients recorded in clinical notes to construct labels of nodes. We have two patients with similar information obtained from their current visits. The green boxes indicate the current data for the two patients. They have different past histories. One is pregnant, while the other has thalassemia. We have extracted information about the patients' pregnancy and thalassemia history from their clinical notes. In the UTTree-H model, patient history is incorporated into the creation of labels, resulting in a unique final sequence for each patient. Blue boxes represent the information used to construct each patient's final sequence. The detailed information (past medical history) makes a difference between the two sets. 
This distinction is critical in assessing patients' similarities. Unlike iron deficiency anemia, identifying patients with thalassemia is vital for avoiding unnecessary iron replacement therapy. Iron overload can lead to several complications in patients with thalassemia [47], impair their immune system, and place them at risk of infection and illness[48].
 
Fig. 4. The effect of paying attention to the concepts extracted from the past history section of clinical notes. Patient 1 is pregnant, while Patient 2 has thalassemia. In the UTTree-H model, patient history is incorporated into the creation of labels, resulting in a unique final sequence for each patient. While these two patients have similar clinical manifestations at the time of admission, they require different treatment methods due to their different medical histories.
